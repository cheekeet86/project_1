{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To analyze the SAT and ACT Tests taken in 2017 and 2018.\n",
    "- To analyze the aggregated scores, participation rates for each state in United States.\n",
    "- Provide recommendations to the College Board to improve participation rates for future tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# visual\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# other\n",
    "import re\n",
    "import os\n",
    "\n",
    "# html\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 2017 data\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "df_sat_2017 = pd.read_csv(path + 'sat_2017.csv')\n",
    "df_act_2017 = pd.read_csv(path + 'act_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_sat_2017\n",
    "\n",
    "df_sat_2017.head(n=10)\n",
    "\n",
    "#df_sat_2017.tail(n=10)\n",
    "#print(len(df_sat_2017))\n",
    "#print(df_sat_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_act_2017\n",
    "\n",
    "df_act_2017.head(n=10)\n",
    "\n",
    "#df_act_2017.tail(n=10)\n",
    "#print(len(df_act_2017))\n",
    "#print(df_act_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2017 SAT Data]\n",
    "\n",
    "- The table shows the SAT scores for all 50 states in United States.\n",
    "- It shows the average scores for 2 sections \"Evidence-Based Reading\" and Writing\" and \"Maths\".\n",
    "- The participation rate and total score are also listed.\n",
    "\n",
    "[2017 ACT Data]\n",
    "\n",
    "- The table shows the ACT scores for all 50 states in United States.\n",
    "- The average scores for 4 sections are listed e.g. \"Science\" and \"Composite\".\n",
    "- The participation rate and composite score (average) are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data looks incomplete. \n",
    "- \"Participation\" lacks clarity and meaning. \n",
    "- Does it mean the participation rate of the entire population or high school students by state?\n",
    "- \"Number of Residents\" or \"Number of Students\" column will be useful to add context for further EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"National\" is listed in df_act_2017['State'] but it is not a US State.\n",
    "- This row should be removed as it shows the the aggregated scores for the different sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SAT SCORING | Evidence-Based Reading | Maths | Total |\n",
    "|---          |---                     |---    |---    |\n",
    "|Max          |800                     |800    |1600   |     \n",
    "|Min          |200                     |200    |400    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ACT SCORING | English| Maths | Reading | Science | Composite |\n",
    "|-------------|--------|-------|---------|---------|-----------|\n",
    "|Max          |36      |36     |36       |36       |36         |    \n",
    "|Min          |1       |1      |1        |1        |1          |\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"National\" row from df_act_2017\n",
    "\n",
    "#print(len(df_act_2017))\n",
    "\n",
    "mask = df_act_2017['State'] == 'National'\n",
    "df_act_2017 = df_act_2017[~mask]\n",
    "\n",
    "df_act_2017.head()\n",
    "\n",
    "#df_act_2017.tail()\n",
    "#print(len(df_act_2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df_sat_2017 (DataType):\\n')\n",
    "print(df_sat_2017.dtypes)\n",
    "print('')\n",
    "print('df_act_2017 (DataType):\\n')\n",
    "print(df_act_2017.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| df_sat_2017                      | input type | correct type |\n",
    "|----------------------------------|------------|--------------|\n",
    "State                              |   object   | string       |\n",
    "Participation                      |   object   | float64      |\n",
    "Evidence-Based Reading and Writing |    int64   | int64        |\n",
    "Math                               |    int64   | int64        |\n",
    "Total                              |    int64   | int64        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| df_act_2017 | input type | correct type |\n",
    "|-------------|------------|--------------|\n",
    "State         |   object   | string       |\n",
    "Participation |   object   | float64      |\n",
    "English       |  float64   | float64      |\n",
    "Math          |  float64   | float64      |\n",
    "Reading       |  float64   | float64      |\n",
    "Science       |  float64   | float64      |\n",
    "Composite     |   object   | float64      |"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_str_to_float(x):  \n",
    "    \n",
    "    if isinstance(x,str) == True:    \n",
    "        x = x.replace('%','')\n",
    "        x = x.replace(')','')\n",
    "        \n",
    "    x = float(x)/100\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat_2017['Participation'] = df_sat_2017['Participation'].apply(percent_str_to_float)\n",
    "df_act_2017['Participation'] = df_act_2017['Participation'].apply(percent_str_to_float)\n",
    "\n",
    "#df_sat_2017\n",
    "#df_act_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_digit_char(x):   \n",
    "    \n",
    "    if isinstance(x,str) == True:\n",
    "        x = re.sub(r'[a-zA-Z]','',x)    \n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = df_sat_2017.columns\n",
    "# skip \"State\" column\n",
    "for col in cols[1:]:\n",
    "    df_sat_2017[col] = df_sat_2017[col].apply(remove_non_digit_char)\n",
    "    \n",
    "cols = df_act_2017.columns\n",
    "# skip \"State\" column\n",
    "for col in cols[1:]:\n",
    "    #print(col)\n",
    "    df_act_2017[col] = df_act_2017[col].apply(remove_non_digit_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"State\" column: object -> string\n",
    "df_sat_2017[\"State\"] = df_sat_2017[\"State\"].astype(str)\n",
    "df_act_2017[\"State\"] = df_act_2017[\"State\"].astype(str)\n",
    "\n",
    "# \"Composite\" column: object -> float\n",
    "df_act_2017[\"Composite\"] = df_act_2017[\"Composite\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df_sat_2017 (DataType):\\n')\n",
    "print(df_sat_2017.dtypes)\n",
    "print('')\n",
    "print('df_act_2017 (DataType):\\n')\n",
    "print(df_act_2017.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sat(col_name):\n",
    "    \n",
    "    if col_name == 'state':\n",
    "        return col_name\n",
    "        \n",
    "    return 'sat_' + col_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_act(col_name):\n",
    "    \n",
    "    if col_name == 'state':\n",
    "        return col_name\n",
    "        \n",
    "    return 'act_' + col_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names -> change to lowercase\n",
    "df_sat_2017.columns = map(str.lower, df_sat_2017.columns)\n",
    "df_act_2017.columns = map(str.lower, df_act_2017.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns with long names\n",
    "df_sat_2017 = df_sat_2017.rename(columns={'evidence-based reading and writing':'read_write'})\n",
    "\n",
    "# add sat_/act_ to column names\n",
    "df_sat_2017.columns = map(add_sat, df_sat_2017.columns)\n",
    "df_act_2017.columns = map(add_act, df_act_2017.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix error (found using histogram much below) in df_sat_2017 \"Maryland\" \"Maths\"\n",
    "\n",
    "mask = df_sat_2017[\"state\"] == \"Maryland\"\n",
    "row = df_sat_2017.loc[mask]\n",
    "\n",
    "print(\"before:\")\n",
    "print(row)\n",
    "\n",
    "total = row[\"sat_total\"]\n",
    "read_write = row[\"sat_read_write\"]\n",
    "math = total - read_write\n",
    "\n",
    "df_sat_2017.loc[mask,\"sat_math\"] = math\n",
    "\n",
    "row = df_sat_2017.loc[mask]\n",
    "print(\"after:\")\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix error (found using histogram much below) in df_act_2017 \"Maryland\" \"Science\"\n",
    "\n",
    "mask = df_act_2017[\"state\"] == \"Maryland\"\n",
    "row = df_act_2017.loc[mask]\n",
    "\n",
    "print(\"before:\")\n",
    "print(row)\n",
    "\n",
    "english = row[\"act_english\"]\n",
    "math = row[\"act_math\"]\n",
    "reading = row[\"act_reading\"]\n",
    "composite = row[\"act_composite\"]\n",
    "\n",
    "science = (composite*4) - english - math - reading\n",
    "print(science)\n",
    "\n",
    "\n",
    "df_act_2017.loc[mask,\"act_science\"] = science\n",
    "\n",
    "row = df_act_2017.loc[mask]\n",
    "print(\"after:\")\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**state**|*string*| SAT / ACT | A region in USA |\n",
    "|**year**|*int*| SAT / ACT | States year the test was taken |\n",
    "|**sat_participation**|*int*| SAT | Percentage of high students who took the SAT Test |\n",
    "|**sat_read_write**|*int*| SAT | Composite score for \"Evidence-Based Reading and Writing\"  |\n",
    "|**sat_math**|*int*| SAT | Composite score for Math |\n",
    "|**sat_total**|*int*| SAT | Total score for SAT Test |\n",
    "|**act_participation**|*int*| ACT | Percentage of high students who took the ACT Test |\n",
    "|**act_english**|*float*| ACT | Composite score for English |\n",
    "|**act_math**|*float*| ACT | Composite score for Math |\n",
    "|**act_reading**|*float*| ACT | Composite score for Reading |\n",
    "|**act_science**|*float*| ACT | Composite score for Science |\n",
    "|**act_composite**|*float*| ACT | Composite score for ACT Test |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no action -> extra row already dropped in earlier cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_sat_2017 with df_act_2017 -> df_2017\n",
    "df_2017 = pd.merge(df_sat_2017,df_act_2017,on='state')\n",
    "\n",
    "# add new column year\n",
    "df_2017.insert(1, 'year', 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output combined 2017 data\n",
    "\n",
    "path = '../output/'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df_2017.to_csv(path + 'combined_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 2018 data\n",
    "\n",
    "path = '../data/'\n",
    "\n",
    "df_sat_2018 = pd.read_csv(path + 'sat_2018.csv')\n",
    "df_act_2018 = pd.read_csv(path + 'act_2018.csv')\n",
    "\n",
    "#df_sat_2018\n",
    "#df_act_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_avg_score(col_name):\n",
    "    col_name = col_name.replace('Average ','')\n",
    "    col_name = col_name.replace(' Score','')\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_nan(value):\n",
    "    if value == 'Not given' or value == None:\n",
    "        print(value)\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data: df_sat_2018 and df_act_2018\n",
    "\n",
    "# split column with state and participation info\n",
    "df_split = df_sat_2018[\"State\"].str.split(\" \\(\", n = 1, expand = True) \n",
    "\n",
    "# add back state and participation columns\n",
    "df_sat_2018[\"State\"] = df_split[0]\n",
    "df_sat_2018[\"Participation\"] = df_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"National\" row\n",
    "mask = df_act_2018['State'] == 'National'\n",
    "df_act_2018 = df_act_2018[~mask]\n",
    "\n",
    "# rename columns directly\n",
    "df_sat_2018 = df_sat_2018.rename(columns={'EBRW':'read_write'})\n",
    "df_act_2018 = df_act_2018.rename(columns={'Percentage of Students Tested':'Participation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values in participation column\n",
    "df_sat_2018[\"Participation\"] = df_sat_2018['Participation'].apply(change_to_nan)\n",
    "df_act_2018[\"Participation\"] = df_act_2018['Participation'].apply(change_to_nan)\n",
    "df_sat_2018['Participation'] = df_sat_2018['Participation'].apply(percent_str_to_float)\n",
    "df_act_2018['Participation'] = df_act_2018['Participation'].apply(percent_str_to_float)\n",
    "\n",
    "# drop irrelevant column\n",
    "df_sat_2018 = df_sat_2018.drop(columns=[\"# of Test Takers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelevant words in column names\n",
    "df_act_2018.columns = map(remove_word_avg_score, df_act_2018.columns)\n",
    "df_act_2018.columns = map(remove_word_avg_score, df_act_2018.columns)\n",
    "\n",
    "# rename column names -> change to lowercase\n",
    "df_sat_2018.columns = map(str.lower, df_sat_2018.columns)\n",
    "df_act_2018.columns = map(str.lower, df_act_2018.columns)\n",
    "\n",
    "# add sat_/act_ to column names\n",
    "df_sat_2018.columns = map(add_sat, df_sat_2018.columns)\n",
    "df_act_2018.columns = map(add_act, df_act_2018.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"object -> string\n",
    "#df_sat_2018[\"state\"] = df_sat_2018[\"state\"].astype(str)\n",
    "#df_act_2018[\"state\"] = df_act_2018[\"state\"].astype(str)\n",
    "\n",
    "# object -> float\n",
    "#df_sat_2018[\"participation\"] = df_sat_2018[\"participation\"].astype(float)\n",
    "#df_act_2018[\"participation\"] = df_act_2018[\"participation\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and create df_2018\n",
    "df_2018 = pd.merge(df_sat_2018,df_act_2018,on='state')\n",
    "\n",
    "# add year column\n",
    "df_2018['year'] = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df_2017 and df_2018\n",
    "df_final = df_2017.append(df_2018,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert percentage e.g. 0.12 to 12\n",
    "\n",
    "df_final['sat_participation'] = df_final['sat_participation'] * 100\n",
    "df_final['act_participation'] = df_final['act_participation'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output combined data\n",
    "\n",
    "path = '../output/'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df_final.to_csv(path + 'final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK!!! act_participation is missing\n",
    "\n",
    "summary = df_final.describe()\n",
    "summary.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stdev(col):\n",
    "    \n",
    "    if is_numeric_dtype(col) == False:\n",
    "        return\n",
    "    \n",
    "    n = len(col)\n",
    "    mean = np.mean(col)\n",
    "    total = 0\n",
    "    \n",
    "    for x in col:\n",
    "        total += (x-mean)**2\n",
    "        \n",
    "    variance = total / n\n",
    "    stdev = np.sqrt(variance)\n",
    "    \n",
    "    print(n,mean,stdev)    \n",
    "    \n",
    "    #return round(stdev,2)\n",
    "    return stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = {col:compute_stdev(df_final[col]) for col in df_final if col != 'state'}\n",
    "\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT? \n",
    "    - 2017 ACT? \n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Highest Participation Rate]\n",
    "\n",
    "- 2017 SAT: District of Columbia, Michigan, Connecticut, Delaware, New Hampshire\n",
    "- 2018 SAT: Colorado, Connecticut, Delaware, Michigan, Idaho\n",
    "- 2017 ACT: Alabama, Kentucky, Wisconsin, Utah, Tennessee\n",
    "- 2018 ACT: Alabama, Kentucky, Wisconsin, Utah, Tennessee\n",
    "\n",
    "[Lowest Participation Rate]\n",
    "\n",
    "- 2017 SAT: North Dakota, Mississippi, Iowa, Missouri, Utah\n",
    "- 2018 SAT: North Dakota, Wyoming, South Dakota, Nebraska, Wisconsin\n",
    "- 2017 ACT: Maine, New Hampshire, Delaware, Rhode Island, Pennsylvania\n",
    "- 2018 ACT: Maine, Rhode Island, New Hampshire, Delaware, North Carolina\n",
    "\n",
    "[Highest Total/Composite Rate]\n",
    "\n",
    "- 2017 SAT: Minnesota, Wisconsin, Iowa, Missouri, Kansas\n",
    "- 2018 SAT: Minnesota, Wisconsin, North Dakota, Iowa, Kansas\n",
    "- 2017 ACT: New Hampshire, Massachusetts, Connecticut, Maine, District of Columbia\n",
    "- 2018 ACT: Connecticut, Massachusetts, New Hampshire, New York, Michigan\n",
    "\n",
    "[Lowest Total/Composite Rate]\n",
    "\n",
    "- 2017 SAT: District of Columbia, Delaware, Idaho, Michigan, Maine\n",
    "- 2018 SAT: District of Columbia, Delaware, West Virginia, Idaho, Michigan\n",
    "- 2017 ACT: Nevada, Mississippi, South Carolina, Hawaii, North Carolina\n",
    "- 2018 ACT: Nevada, South Carolina, Mississippi, Hawaii, Alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create masks\n",
    "mask_2017 = df_final['year'] == 2017\n",
    "mask_2018 = df_final['year'] == 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2017 highest participation rates\n",
    "df_sat_2017_high_participation = df_final[mask_2017].sort_values('sat_participation',ascending=False)\n",
    "df_sat_2017_high_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2018 highest participation rates\n",
    "df_sat_2018_high_participation = df_final[mask_2018].sort_values('sat_participation',ascending=False)\n",
    "df_sat_2018_high_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2017 highest participation rates\n",
    "df_act_2017_high_participation = df_final[mask_2017].sort_values('act_participation',ascending=False)\n",
    "df_act_2017_high_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2018 highest participation rates\n",
    "df_act_2018_high_participation = df_final[mask_2018].sort_values('act_participation',ascending=False)\n",
    "df_act_2018_high_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2017 lowest participation rates\n",
    "df_sat_2017_low_participation = df_final[mask_2017].sort_values('sat_participation',ascending=True)\n",
    "df_sat_2017_low_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2018 lowest participation rates\n",
    "df_sat_2018_low_participation = df_final[mask_2018].sort_values('sat_participation',ascending=True)\n",
    "df_sat_2018_low_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2017 lowest participation rates\n",
    "df_act_2017_low_participation = df_final[mask_2017].sort_values('act_participation',ascending=True)\n",
    "df_act_2017_low_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2018 lowest participation rates\n",
    "df_act_2018_low_participation = df_final[mask_2018].sort_values('act_participation',ascending=True)\n",
    "df_act_2018_low_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2017 highest total score\n",
    "df_sat_2017_high_total = df_final[mask_2017].sort_values('sat_total',ascending=False)\n",
    "df_sat_2017_high_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2018 highest total score\n",
    "df_sat_2018_high_total = df_final[mask_2018].sort_values('sat_total',ascending=False)\n",
    "df_sat_2018_high_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2017 highest composite score\n",
    "df_act_2017_high_composite = df_final[mask_2017].sort_values('act_composite',ascending=False)\n",
    "df_act_2017_high_composite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2018 highest composite score\n",
    "df_act_2018_high_composite = df_final[mask_2018].sort_values('act_composite',ascending=False)\n",
    "df_act_2018_high_composite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2017 lowest total score\n",
    "df_sat_2017_low_total = df_final[mask_2017].sort_values('sat_total',ascending=True)\n",
    "df_sat_2017_low_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT 2018 lowest total score\n",
    "df_sat_2018_low_total = df_final[mask_2018].sort_values('sat_total',ascending=True)\n",
    "df_sat_2018_low_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2017 lowest composite score\n",
    "df_act_2017_low_composite = df_final[mask_2017].sort_values('act_composite',ascending=True)\n",
    "df_act_2017_low_composite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT 2018 lowest composite score\n",
    "df_act_2018_low_composite = df_final[mask_2018].sort_values('act_composite',ascending=True)\n",
    "df_act_2018_low_composite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final heatmap\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.heatmap(df_final.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final pairplots\n",
    "sns.pairplot(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "\n",
    "#def subplot_histograms(df, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    #nrows = int(np.ceil(len(list_of_columns)/2) # Makes sure you have enough rows\n",
    "    #fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    #ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    #for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        #ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified\n",
    "\n",
    "def subplot_histograms(df,rows,cols,titles,xlabels,ylabels,ylims,bins):\n",
    "    \n",
    "    # Makes sure you have enough rows\n",
    "    nrows = len(rows)   \n",
    "    ncols = len(rows)    \n",
    "    #print(nrows,ncols)\n",
    "                \n",
    "    # You'll want to specify your figsize            \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols,figsize=(16,12))\n",
    "                \n",
    "    # Ravel turns a matrix into a vector, which is easier to iterate            \n",
    "    ax = ax.ravel()\n",
    "    index = 0\n",
    "                \n",
    "    # Gives us an index value to get into all our lists            \n",
    "    for i, row in enumerate(rows):\n",
    "        for j, col in enumerate(cols):\n",
    "                \n",
    "            #print(i,j)\n",
    "            \n",
    "            # feel free to add more settings        \n",
    "            ax[index].hist(df[row][col],bins=bins)\n",
    "\n",
    "            # Set titles, labels, etc here for each subplot\n",
    "            ax[index].set_title(titles[index]) \n",
    "            ax[index].set_xlabel(xlabels)\n",
    "            ax[index].set_ylabel(ylabels)\n",
    "            ax[index].set_ylim(ylims[0],ylims[1])\n",
    "            \n",
    "            index += 1           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participation Rates for SAT & ACT\n",
    "\n",
    "rows = [mask_2018,mask_2017]\n",
    "cols = ['sat_participation','act_participation']\n",
    "titles = ['SAT 2018','ACT 2018','SAT 2017','ACT 2017']\n",
    "xlabels = 'Percentage'\n",
    "ylabels = 'No of States'\n",
    "ylims = [0,25]\n",
    "bins = 10\n",
    "\n",
    "print(\"Participation Rates\")\n",
    "subplot_histograms(df_final,rows,cols,titles,xlabels,ylabels,ylims,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math scores for SAT & ACT\n",
    "\n",
    "# Participation Rates for SAT & ACT\n",
    "\n",
    "rows = [mask_2018,mask_2017]\n",
    "cols = ['sat_math','act_math']\n",
    "titles = ['SAT 2018','ACT 2018','SAT 2017','ACT 2017']\n",
    "xlabels = 'Scores'\n",
    "ylabels = 'Percentage'\n",
    "ylims = [0,10]\n",
    "bins = 15\n",
    "\n",
    "print(\"Math Scores\")\n",
    "subplot_histograms(df_final,rows,cols,titles,xlabels,ylabels,ylims,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column: average(act_english,act_reading) = act_verbal\n",
    "df_final[\"act_verbal\"] = (df_final[\"act_english\"] + df_final[\"act_reading\"]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/verbal scores for SAT & ACT\n",
    "\n",
    "rows = [mask_2018,mask_2017]\n",
    "cols = ['sat_read_write','act_verbal']\n",
    "titles = ['SAT 2018','ACT 2018','SAT 2017','ACT 2017']\n",
    "xlabels = 'Scores'\n",
    "ylabels = 'No of States'\n",
    "ylims = [0,10]\n",
    "bins = 15\n",
    "\n",
    "print(\"Reading/Verbal Scores\")\n",
    "subplot_histograms(df_final,rows,cols,titles,xlabels,ylabels,ylims,bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatterplot(title,x,y,xlabel=None,ylabel=None,regplot=False):\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel = x.name\n",
    "    if ylabel == None:\n",
    "        ylabel = y.name   \n",
    "        \n",
    "    if regplot:\n",
    "        sns.regplot(x=x,y=y)\n",
    "    else:\n",
    "        sns.scatterplot(x=x,y=y)\n",
    "                    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_final[mask_2017]\n",
    "df_2018 = df_final[mask_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT math scores for 2017\n",
    "\n",
    "x = df_2017['act_math']\n",
    "y = df_2017['sat_math']\n",
    "title = (\"SAT vs. ACT math scores for 2017\")\n",
    "\n",
    "create_scatterplot(title,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT verbal/reading scores for 2017\n",
    "\n",
    "x = df_2017['act_verbal']\n",
    "y = df_2017['sat_read_write']\n",
    "title = (\"SAT vs. ACT verbal/reading scores for 2017\")\n",
    "         \n",
    "create_scatterplot(title,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT total/composite scores for 2017\n",
    "\n",
    "x = df_2017['act_composite']\n",
    "y = df_2017['sat_total']\n",
    "title = (\"SAT vs. ACT total/composite scores for 20177\")\n",
    "         \n",
    "create_scatterplot(title,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total scores for SAT 2017 vs. 2018\n",
    "\n",
    "x = df_2018['sat_total']\n",
    "y = df_2017['sat_total']\n",
    "title = (\"Total scores for SAT 2017 vs. 2018\")\n",
    "         \n",
    "create_scatterplot(title,x,y,2018,2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "x = df_2018['act_composite']\n",
    "y = df_2017['act_composite']\n",
    "title = (\"Composite scores for ACT 2017 vs. 2018\")\n",
    "         \n",
    "create_scatterplot(title,x,y,2018,2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_2017(col_name):\n",
    "    return col_name + '_2017'\n",
    "\n",
    "def add_2018(col_name):\n",
    "    return col_name + '_2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot(data,xlabel):\n",
    "    \n",
    "    g = sns.boxplot(data=data)\n",
    "    #g.set(xlabel=xlabel)\n",
    "    g.set(xticklabels=xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual scores for SAT\n",
    "\n",
    "cols = ['sat_read_write','sat_math']\n",
    "\n",
    "df_sat_2017 = df_2017[cols]\n",
    "df_sat_2018 = df_2018[cols]\n",
    "\n",
    "df_sat_2017.columns = map(add_2017, df_sat_2017.columns)\n",
    "df_sat_2018.columns = map(add_2018, df_sat_2018.columns)\n",
    "\n",
    "# combine 2017 and 2018 scores\n",
    "df_sat = pd.concat([df_sat_2017, df_sat_2018], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "new_order = ['sat_read_write_2017','sat_read_write_2018','sat_math_2017','sat_math_2018']\n",
    "df_sat = df_sat.reindex(columns=new_order)\n",
    "\n",
    "xlabels = ['Verbal 2017','Verbal 2018','Math 2017','Math 2018']\n",
    "create_boxplot(df_sat,xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total scores for SAT\n",
    "\n",
    "cols = ['sat_total']\n",
    "\n",
    "df_sat_2017 = df_2017[cols]\n",
    "df_sat_2018 = df_2018[cols]\n",
    "\n",
    "df_sat_2017.columns = map(add_2017, df_sat_2017.columns)\n",
    "df_sat_2018.columns = map(add_2018, df_sat_2018.columns)\n",
    "\n",
    "# combine 2017 and 2018 scores\n",
    "df_sat = pd.concat([df_sat_2017, df_sat_2018], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = ['Total 2017','Total 2018']\n",
    "create_boxplot(df_sat,xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores for ACT 2017\n",
    "\n",
    "cols = ['act_english','act_math','act_reading','act_science','act_composite']\n",
    "df_act_2017 = df_2017[cols]\n",
    "\n",
    "xlabels = ['English','Math','Reading','Science','Composite']\n",
    "create_boxplot(df_act_2017,xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores for ACT 2018\n",
    "\n",
    "cols = ['act_english','act_math','act_reading','act_science','act_composite']\n",
    "df_act_2018 = df_2018[cols]\n",
    "\n",
    "xlabels = ['English','Math','Reading','Science','Composite']\n",
    "create_boxplot(df_act_2018,xlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT math participation for 2017\n",
    "\n",
    "x = df_2017['act_participation']\n",
    "y = df_2017['sat_participation']\n",
    "title = (\"SAT vs. ACT math participation for 2017\")\n",
    "         \n",
    "create_scatterplot(title,x,y,regplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAT vs. ACT math participation for 2018\n",
    "\n",
    "x = df_2018['act_participation']\n",
    "y = df_2018['sat_participation']\n",
    "title = (\"SAT vs. ACT math participation for 2018\")\n",
    "         \n",
    "create_scatterplot(title,x,y,regplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done using Excel\n",
    "\n",
    "path = '../images/'\n",
    "Image(filename = path + \"map.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| variable | distribution | remarks |\n",
    "|---|---|---|\n",
    "| sat_participation | bimodal | 2 peaks at min and max |\n",
    "| sat_read_write | bimodal | |\n",
    "| sat_math | bimodal | |\n",
    "| sat_total | bimodal | |\n",
    "| act_participation | bimodal | 2 peaks at min and max |\n",
    "| act_english | bimodal | |\n",
    "| act_math | bimodal | |   \n",
    "| act_reading | bimodal | |\n",
    "| act_science | bimodal | |\n",
    "| act_composite | bimodal | |\n",
    "| act_verbal | bimodal | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Bimodal is a type of Normal Distribution i.e. 2 Normal Distributions with different Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_matrix(df,nrows=2,ncols=2,bins=15):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20,8))    \n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    color = 'r'\n",
    "    \n",
    "    for i, col in enumerate(df):\n",
    "        \n",
    "        if 'act_' in col:\n",
    "            color = 'r'\n",
    "        if 'sat_' in col:\n",
    "            color = 'b'        \n",
    "        \n",
    "        #ax[index].hist(df[col], bins=bins)\n",
    "        sns.distplot(df[col], hist=True, bins=bins, ax=ax[index],color=color)\n",
    "\n",
    "        ax[index].set_title(col) \n",
    "        ax[index].set_xlabel('')            \n",
    "\n",
    "        index += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['state','year','act_verbal']\n",
    "df_final_2 = df_final.drop(cols,axis=1)\n",
    "histogram_matrix(df_final_2,2,5,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yes to certain extend.\n",
    "- Data shows bimodal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maths: Yes. Has 2 peaks. Peak #1 (with lower mean) has lower variance compared to Peak #2 (with higher mean).\n",
    "- Reading. Same observation as Maths.\n",
    "- Rates. Yes. Has 2 peaks at min and max values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No\n",
    "- Population size of Class of 2017 and 2018 are not given for each state.\n",
    "- Without population size it may not be possible to compare participation rate, scores between states, year or tests (SAT or ACT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores? \n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ACT vs SAT: 11 Key Differences to Help You Pick the Right Test] (https://blog.prepscholar.com/act-vs-sat)\n",
    "\n",
    "- Time given to complete each question is different.\n",
    "- SAT has a non-Calculator subsection. Not applicable for ACT.\n",
    "- Different math topics are tested e.g. more focus in geometry for ACT and matrics tested in SAT.\n",
    "\n",
    "Conclusion: Not appropriate to compare the SAT and ACT math scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: The difference of SAT participation rate between 2017 and 2018 is zero.\n",
    "# H1: The difference of SAT participation rate between 2017 and 2018 is not zero.\n",
    "# alpha = 0.05\n",
    "\n",
    "sat_part_2017 = list(df_final[mask_2017]['sat_participation'])\n",
    "sat_part_2018 = list(df_final[mask_2018]['sat_participation'])\n",
    "\n",
    "print(np.mean(sat_part_2017))\n",
    "print(np.mean(sat_part_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(sat_part_2017, sat_part_2018)\n",
    "print(t_stat, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_value > alpha\n",
    "# 0.34967 > 0.05\n",
    "\n",
    "# conclusion:\n",
    "# insufficient evidence to reject H0 -> The difference of SAT participation rate between 2017 and 2018 is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points on the x axis between -4 and 4:\n",
    "xpoints = np.linspace(-4, 4, 500)\n",
    "\n",
    "# Use `stats.t.pdf` to get values on the probability density function for the t-distribution.\n",
    "# The second argument is the degrees of freedom: n1 + n2 - 2.\n",
    "ypoints = stats.t.pdf(xpoints, (50+50-2), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a `matplotlib` \"figure.\"\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "# Get the current \"axis\" out of the figure.\n",
    "ax = fig.gca()\n",
    "\n",
    "# Plot the lines using `matplotlib`'s plot function:\n",
    "ax.plot(xpoints, ypoints, linewidth=3, color='darkred')\n",
    "\n",
    "# Plot a vertical line for our measured difference in rates' t-statistic.\n",
    "ax.axvline(t_stat, color='black', linestyle='--', lw=5)\n",
    "ax.axvline(-t_stat, color='black', linestyle='--', lw=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_2017 = len(sat_part_2017)\n",
    "#n_2018 = len(sat_part_2018)\n",
    "#lower_tail = stats.t.cdf(-abs(t_stat), n_2017+n_2018-2)\n",
    "#upper_tail = 1. - stats.t.cdf(abs(t_stat), n_2017+n_2018-2)\n",
    "#p_value_man = lower_tail+upper_tail\n",
    "#print(p_value)\n",
    "#print(p_value_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find states with high participation rates for both tests\n",
    "\n",
    "df_final[\"total_participation\"] = df_final[\"sat_participation\"] + df_final[\"act_participation\"]\n",
    "df_final.sort_values(by=\"total_participation\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states with low participation rates for both tests\n",
    "df_final.sort_values(by=\"total_participation\",ascending=True).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st state: Florida (high participation rates for both tests)\n",
    "\n",
    "mask_florida = df_final['state'] == 'Florida'\n",
    "df_florida = df_final[mask_florida]\n",
    "df_florida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Which States Require Students to Take the SAT or ACT?] (https://www.edweek.org/ew/section/multimedia/states-require-students-take-sat-or-act.html)\n",
    "\n",
    "- Students in Florida must pass exit exams or achieve specified scores on ACT or SAT.\n",
    "\n",
    "[SAT, ACT: Florida students lag behind national averages] (https://www.orlandosentinel.com/news/education/os-ne-act-sat-florida-scores-20181024-story.html)\n",
    "\n",
    "- There is a 14% participation rate increase for SAT test in Florida between 2017 and 2018.\n",
    "- This is because of free tests sessions provided by the schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd state: Colorado (biggest delta for participation rates for SAT/ACT 2017/2018)\n",
    "\n",
    "mask_colorado = df_final['state'] == 'Colorado'\n",
    "df_colorado = df_final[mask_colorado]\n",
    "df_colorado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Which States Require Students to Take the SAT or ACT?] (https://www.edweek.org/ew/section/multimedia/states-require-students-take-sat-or-act.html)\n",
    "\n",
    "- SAT/PSAT are required tests for high school students in Colorado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Colorado juniors face new, revamped college exam in SAT after state dumps rival ACT] (https://www.denverpost.com/2017/03/06/colorado-juniors-sat-college-exam/)\n",
    "\n",
    "- The Colorado state decided to switch from ACT to SAT in 2015.\n",
    "- The SAT test was better aligned with the high school Colorado Academic Standards.\n",
    "- The College Board (which administrates the SAT test) also provides more education resources for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd state: Iowa (low participations rates overall for both tests)\n",
    "\n",
    "mask_iowa = df_final['state'] == 'Iowa'\n",
    "df_iowa = df_final[mask_iowa]\n",
    "df_iowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Which States Require Students to Take the SAT or ACT?] (https://www.edweek.org/ew/section/multimedia/states-require-students-take-sat-or-act.html)\n",
    "\n",
    "- Both SAT and ACT are not required for Iowa.\n",
    "\n",
    "[The History Of ACT Test] (https://www.testpreptoolkit.com/act-test/the-history-of-act-test)\n",
    "\n",
    "- ACT was created by a University of Iowa professor (Everett Franklin Lindquist) in 1959.\n",
    "- Influence students to take ACT instead of SAT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Recommendations for Iowa]\n",
    "\n",
    "1. Provide free test sessions for SAT tests.\n",
    "2. Iowa Education Board should enforce either SAT or ACT tests for college admissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Additional Data For Further Investigations]\n",
    "\n",
    "1. College admission requirements for all colleges and universities in Iowa.\n",
    "2. SAT and ACT test trends for 5 to 10 years.\n",
    "3. Education demographic in Iowa (e.g. figures for high-school/college/university graduates)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
